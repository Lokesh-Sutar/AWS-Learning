# S3
- Object level storage
- One of the important and cost effective service
- It stores different types of data like Photos, Audio, and Videos as Objects.

## Types of S3 Entities

### 1. Bucket
- A bucket is a container for objects stored in Amazon S3
- Is like main folder were you can upload your files and folders (Objects).
- You can create 100 Buckets per account.
- All the data stored inside the bucket is **Encrypted**
- Bucket should be empty before deleting the bucket.

#### Rules for Bucket Creation-
- Bucket names must be globally unique across all of AWS. No two buckets can have the same name.
- Must be between 3 and 63 characters long.
- Can only contain lowercase letters, numbers, hyphens (-), and periods (.), **No Uppercase letters**.
- Must start and end with a lowercase letter or number.
- Should not be formatted as IP addresses (e.g., 192.168.1.1).
- A bucket has no limit to the amount of objects that it can store.
- No bucket can exist inside of other buckets.
- You can create up to 100 buckets in each of your AWS cloud accounts, with no limit on the number of objects you can store in a bucket.


### 2. Object
- Every entities (files & folders) are called objects
- Maximum size of each object is 5TB
- No limitation on number of objects to upload

### 3. Key
- A key is a unique identifier for an object.
- It is basically a path to locate the object.
- Every object in a bucket is associated with one key.
- eg. `key:Bucket123/folder1/file1.txt`


## Versioning in S3
- Versioning is a means of keeping multiple variants of an object in the same bucket
- It is like git version control system
- Every latest changes in file will become **current version**
- When you delete an object in a versioned bucket, S3 does not permanently remove the object. Instead, it creates a "delete marker" that becomes the current version. The actual object still exists and can be restored if needed by deleting the "delete marker" object.
- To delete the object permanently you have to enable "Show Versions" and then delete versions of file.

### Use Case
- To Store codes/repo
- To Host Website
- To Store Backups

## Storage Classes

### 1. Standard Storage Class
- This is default Storage Class.
- Ensures Durability of 99.999999999% (11 9’s) and Availability of 99.99%.
- Used for Frequently accessed data where low latency is critical.
- This is most expensive storage class.
- Charges according to size of data.
- Whenever you upload a data, it remains in "standard storage class" for initial 30 days.

### 2. S3 Standard-Infrequent Access
- Used for less accessed data
- Good for backups
- Less Charges as compared to "Standard Storage Class"
- Charges according to number of access, not on size of data

### 3. S3 One Zone-Infrequent Access
- Used to store re-creatable data
- Charges are less as compared to "S3 Standard-Infrequent Access"
- Stores data in a single Availability Zone
- Provides you the same high durability, high throughput, and low latency as in "Standard Storage Class"
- Ensures Durability of 99.999999999% (11 9’s) and Availability of 99.5%.

### 4. S3 Intelligent-Tiering
- Automated Cost Optimization for Data with Unknown Access Patterns
- Optimizes costs by automatically moving objects between two access tiers (frequent and infrequent) based on changing access patterns.
- Ensures Durability of 99.999999999% (11 9’s) and Availability of 99.99%.
- Used for Data with unknown or changing access patterns.

### 5. S3 Glacier
- It designed for long-term archival and infrequent access.
- High Latency (Retrival Time/Speed)
- Used for Long-term archival storage with retrieval times ranging from minutes to hours.
- Ensures Durability of 99.999999999% (11 9’s) and Availability of 99.99%.
- Cost is Very low for storage and retrieval costs vary based on retrieval speed.

### 6. S3 Glacier Deep Archive
- It is lowest-cost storage class within Amazon S3
- Specifically designed for long-term archival of data that is rarely accessed.
- Used for Long-term archival of data that is rarely accessed, with retrieval times of up to 12 hours.
- Ensures Durability of 99.999999999% (11 9’s) and Availability of 99.99%.

## Encryption
- Protection our data from unauthorized/public access
- Encryption in Amazon S3 refers to the process of protecting data by converting it into a format that is unreadable to unauthorized users.
- Only someone with the correct encryption key can decrypt and access the original data.
- Amazon S3 offers a variety of encryption options to protect your data at rest (while it's stored in S3) and in transit (as it's uploaded or downloaded).
- Since January 2023, Amazon S3 automatically encrypts all new object uploads to all buckets using Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) as the default.

### Types of Encryption
1. Client-Side Encryption
    - Data is encrypted on the client side (your device) before it is sent to the server. Only the encrypted data is stored or transmitted.
    - The server stores the encrypted data but never sees the unencrypted data or keys.
    - You encrypt data before uploading it to S3, and decrypt it after downloading.
    - You manage your own keys and encryption process.
    - More secure but also more complex.
    - AWS SDKs can help implement client-side encryption using KMS or custom keys.

2. Server-Side Encryption
    - Data is encrypted by the server after it is received from the client. The server manages the encryption and decryption processes.
    - Encryption is handled by AWS, and data is automatically encrypted before being written to disk, and automatically decrypted when you access it.
    - You don’t need to change your application logic to use SSE.
    - Types of Server-Side Encryption:
        1. Server-Side Encryption with S3-Managed Keys (SSE-S3):
            - This is the default for all new object uploads.
            - S3 handles all the key management for you.
            - It uses a strong encryption algorithm (AES-256).
            - Each object is encrypted with a unique key, which is then encrypted with a master key that is regularly rotated by S3.

        2. Server-Side Encryption with AWS Key Management Service (SSE-KMS):
            - This method integrates S3 with the AWS Key Management Service (KMS).
            - It provides more control and an audit trail over the keys used to encrypt your data.
            - You can use a default AWS-managed KMS key or a customer-managed key.
            - Slightly more expensive than SSE-S3.

        3. Server-Side Encryption with Customer-Provided Keys (SSE-C):
            - You generate and supply your own encryption key when uploading and downloading objects.
            - AWS uses it to encrypt/decrypt the object, but never stores the key.
            - You are fully responsible for key management.

## Management
- It is a part of S3 Bucket
- Used to create Rules for changing storage class, deletion, making copies, Invetory Configurations. 

### Lifecycle Rules
- Manages Transition, Deletion, Deletion of multipart downloads like operations
- It applicable to specific objects with fixed prefix OR all objects.
- Used to automatically change storage class after certain days (Transitioning).

### Replication Rules
- Used to create copies of objects in bucket
- Can create copies into same region or another region(cross region)
- Requires to mention IAM Role, otherwise the IAM Role gets created automatically
- We cannot choose same bucket as Destination Bucket
- Versioning should be enabled in Destination Bucket

## Static Web Hosting
To host the website:
- Enable 'Static website hosting' from Bucket -> Properties
    - You will get a static URL for your website.
- Disable 'Block public access' from Bucket -> Permissions
- Add 'Bucket policy' from Bucket -> Permissions:
    - Use AWS Policy Builder - https://awspolicygen.s3.amazonaws.com/policygen.html
        - Type of Policy: Select 'S3 Bucket Policy'
            1. Resource Based
                - Can be attached to services like EC2, S3, etc...
            2. Indentity Based 
                - Can be attached to user, groups and roles.
        - principal: *
        - Action: GetObject
        - Amazon Resource Name: Bucket-ARN
        - Generate Policy -> Copy JSON
    - Paste Copied JSON into Bucket policy
- Your Website is ready.